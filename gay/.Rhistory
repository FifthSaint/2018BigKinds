# 숫자 변수와 문자 변수를 결합해 분석해 볼까요
Desc(delivery_min ~ area, d.pizza)
# 숫자 변수와 문자 변수를 결합해 분석해 볼까요
Desc(delivery_min ~ area, d.pizza)
# 문자 변수끼리 결합하면 어떤 결과가 나올까요?
Desc(area ~ driver, d.pizza)
# 문자 변수끼리 결합하면 어떤 결과가 나올까요?
Desc(area ~ driver, d.pizza)
install.packages("DescTools")
# 사용을 위해 라이브러리 등록을 해줍니다
library(DescTools)
# 사용을 위해 라이브러리 등록을 해줍니다
library(DescTools)
install.packages("DescTools")
# 사용을 위해 라이브러리 등록을 해줍니다
library(DescTools)
install.packages("RDCOMClient")
install.packages("RDCOMClient", repos = "http://www.omegahat.net/R")
library(RDCOMClient)
XLGetRange(header=TRUE)
XLGetRange(header=TRUE)
mydata <- XLGetRange(header=TRUE)
View(mydata)
XLView(d.pizza)
Desc(d.pizza$temperature)
Desc(d.pizza$driver)
Desc(temperature ~ delivery_min, d.pizza)
# 숫자 변수와 문자 변수를 결합해 분석해 볼까요
# 배달 시간과 지역의 관계를 한번 살펴 봅니다
Desc(delivery_min ~ area, d.pizza)
# 문자 변수끼리 결합하면 어떤 결과가 나올까요?
Desc(area ~ driver, d.pizza)
install.packages("rvest")
install.packages("dplyr")
url <- "http://www.hani.co.kr/arti/science/home01.html"
read_html(url)
library(rvest)
library(dplyr)
read_html(url)
html <- read_html(url)
html %>%
html_nodes("#contents-section > div.section-animal > div.animal-top > div.animal-top-article > h4 > a")
html %>%
html_nodes("#contents-section > div.section-animal > div.animal-top > div.animal-top-article > h4 > a")
html %>%
html_nodes("#contents-section > div.section-animal > div.animal-top > div.animal-top-article > h4 > a")
html %>%
html_nodes("#contents-section > div.section-animal > div.animal-top > div.animal-top-article > h4 > a") %>%
html_text()
url <- "http://www.hani.co.kr/arti/science/technology/868357.html"
html <- read_html(url)
html %>%
html_nodes("#a-left-scroll-in > div.article-text > div > div.text") %>%
html_text()
text <- html %>%
html_nodes("#a-left-scroll-in > div.article-text > div > div.text") %>%
html_text()
text
headline <- html %>%
html_nodes("#article_view_headline > h4 > span") %>%
html_text()
text <- html %>%
html_nodes("#a-left-scroll-in > div.article-text > div > div.text") %>%
html_text()
result <- data.frame( 제목=headline,
본문=text)
View(result)
install.packages("shiny")
library(shiny)
runExample("01_hello")
runExample("01_hello")
# Define UI for app that draws a histogram ----
ui <- fluidPage(
# App title ----
titlePanel("Hello Shiny!"),
# Sidebar layout with input and output definitions ----
sidebarLayout(
# Sidebar panel for inputs ----
sidebarPanel(
# Input: Slider for the number of bins ----
sliderInput(inputId = "bins",
label = "Number of bins:",
min = 1,
max = 50,
value = 30)
),
# Main panel for displaying outputs ----
mainPanel(
# Output: Histogram ----
plotOutput(outputId = "distPlot")
)
)
)
# Histogram of the Old Faithful Geyser Data ----
# with requested number of bins
# This expression that generates a histogram is wrapped in a call
# to renderPlot to indicate that:
#
# 1. It is "reactive" and therefore should be automatically
#    re-executed when inputs (input$bins) change
# 2. Its output type is a plot
output$distPlot <- renderPlot({
x    <- faithful$waiting
bins <- seq(min(x), max(x), length.out = input$bins + 1)
hist(x, breaks = bins, col = "#75AADB", border = "white",
xlab = "Waiting time to next eruption (in mins)",
main = "Histogram of waiting times")
})
# Define server logic required to draw a histogram ----
server <- function(input, output) {
# Histogram of the Old Faithful Geyser Data ----
# with requested number of bins
# This expression that generates a histogram is wrapped in a call
# to renderPlot to indicate that:
#
# 1. It is "reactive" and therefore should be automatically
#    re-executed when inputs (input$bins) change
# 2. Its output type is a plot
output$distPlot <- renderPlot({
x    <- faithful$waiting
bins <- seq(min(x), max(x), length.out = input$bins + 1)
hist(x, breaks = bins, col = "#75AADB", border = "white",
xlab = "Waiting time to next eruption (in mins)",
main = "Histogram of waiting times")
})
}
shinyApp(ui, server)
install.packages("googleVis")
library(googleVis)
M1 <- gvisMotionChart(Fruits, idvar="Fruit", timevar="Year")
plot(M1)
M1 <- gvisMotionChart(Fruits, idvar="Fruit", timevar="Year")
plot(M1)
#2018 언론진흥재단 뉴스빅데이터 '소수자 키워드' 프로젝
#현재의 디렉토리주소 알아보기
getwd()
#디렌토리 주소 재설정
setwd("C:/Users/hannews/Documents/GitHub")
#디렌토리 주소 재설정
getwd()
#폴더 안의 파일들 확인하기
list.files()
#디렌토리 주소 재설정
setwd("C:/Users/hannews/Documents/GitHub/2018BigKinds")
#폴더 안의 파일들 확인하기
list.files()
#디렌토리 주소 재설정
setwd("C:/Users/hannews/Documents/GitHub/2018BigKinds/gay")
#폴더 안의 파일들 확인하기
list.files()
library(readxl)
# 저장된 엑셀데이터 불러오기
data <- read_excel("동성애.xlsx")
library(dplyr)
udata <- data[((data$"분석제외 여부" != "중복") & (data$"분석제외 여부" !="중복, 예외"))|is.na(data$"분석제외 여부"),]
# 연도별로 데이터 나누기
year <- c(1990:2018)
for (val in year)
{
nam <- paste("data", val, sep = "")
assign(nam, subset(udata, grepl(paste0("^",val), 일자)))
}
library(tm)
library(KoNLP)
## 사전 선택 택1
# useSejongDic()
useNIADic()
library(stringr)
### tempdata에서 콘텐츠(본문) 부분만 따오기 이후의 코드를
### ext50 펑션으로 정의 그러나 톱 30으로 바꾸었음
ext50 <- function(data, year) {
contents <- data$'본문'
# head(contents)
#영문표현삭제
newcontents <- str_replace_all(contents, "[[:lower:]]", "")
#제어문자 삭제
newcontents <- str_replace_all(newcontents, "[[:cntrl:]]", "")
#특수기호 삭제
newcontents <- str_replace_all(newcontents, "[[:punct:]]", "")
#숫자 = 삭제
newcontents <- str_replace_all(newcontents, "[[:digit:]]", "")
#괄호삭제
newcontents <- str_replace_all(newcontents, "\\(", "")
newcontents <- str_replace_all(newcontents, "\\)", "")
#따옴표 삭제
newcontents <- str_replace_all(newcontents, "'", "")
newcontents <- str_replace_all(newcontents, "'", "")
noun <- extractNoun(newcontents)
##불용어처리
txt_data <- gsub("//d+","",noun)
txt_data <- gsub("[[:cntrl:]]","",txt_data)
txt_data <- gsub("[[:punct:]]","",txt_data)
#이녀석이 숫자를 삭제해줍니다.
txt_data <- gsub("[[:digit:]]","",txt_data)
txt_data <- gsub("[[:lower:]]","",txt_data)
txt_data <- gsub("[[:upper:]]","",txt_data)
txt_data <- gsub("[A-z]","",txt_data)
txt_data <- gsub("'","",txt_data)
txt_data <- gsub("'","",txt_data)
txt_data <- gsub("‘","",txt_data)
txt_data <- gsub("’","",txt_data)
# head(txt_data)
myCorpus <- Corpus(VectorSource(txt_data))
myCorpus <- tm_map(myCorpus, removePunctuation)
myCorpus <- tm_map(myCorpus, removeNumbers)
myCorpus <- tm_map(myCorpus, tolower)
myCorpus <- tm_map(myCorpus, stripWhitespace)
WordList <- sapply(myCorpus, extractNoun, USE.NAMES=FALSE)
vectordata <- unlist(WordList)
vectordata <- Filter(function(x){nchar(x)>1}, vectordata)
# preview<- sort(table(vectordata), decreasing=TRUE,100)
# View(preview)
#빈도추출
wordcount <- table(vectordata)
# write.csv(wordcount,file="freq.csv")
#상위빈도로 정렬해서 result2로 명명
#result2 <- sort(wordcount, decreasing=TRUE)
# View(result2)
#누적빈도 알아보기
#cumsum.word.freq <-cumsum(result2)
#cumsum.word.freq[1:50]
#전체합이1이되는비율알아보기
#prop.word.freq <-cumsum.word.freq/cumsum.word.freq[length(cumsum.word.freq)]
#prop.word.freq[1:100]
#상위빈도 50단어 저장
result <- head(sort(wordcount, decreasing=TRUE), n=50)
#데이터프레임으로 변환
df.result <-data.frame(result)
#연도 추가
df.result$year <-year
#순위 추가
df.result$rank <-rank(df.result$Freq)
return(df.result)
} # ext50 펑션 정의 끝
# 1990~2018 연도별 단어 추출
for (val in year)
{
nam1 <- paste("data", val, sep ="")
nam2 <- paste("words", val, sep ="")
assign(nam2, ext50(eval(parse(text=nam1)), val))
#print(nam2$일자)
}
View(words1990)
typeof(words1990)
test <- c(words1990, 1991)
View(test)
typeof(test)
test <- c(words1990, words1991)
View(test)
View(test)
test$Freq
df.test <- data.frame(test)
View(df.test)
typeof(words1990)
View(words1990)
View(words1990)
test <- merge(words1990, words1991, by.x="vectordata", by.y="year")
View(test)
test <- merge(words1990, words1991, by="vectordata", by.y="year")
typeof(data2016)
x <- list(station="Vinadio", elev=1200, month = c("N", "D", "J"), snowdepth=c(6,212,44))
x
View(x)
View(words2009)
table(x)
y <- data.frame(x)
View(y)
x <- data.frame(words1990)
x <- data.frame(words1991)
merge(x, y, by.x="vectordata", by.y="year")
m <- cbind(1, 1:7)
View(m)
m <- cbind(words1990, words1991)
m <- rbind(words1990, words199)
m <- rbind(words1990, words1991)
View(m)
View(words1991)
### tempdata에서 콘텐츠(본문) 부분만 따오기 이후의 코드를
### ext50 펑션으로 정의 그러나 톱 30으로 바꾸었음
ext50 <- function(data, year) {
contents <- data$'본문'
# head(contents)
#영문표현삭제
newcontents <- str_replace_all(contents, "[[:lower:]]", "")
#제어문자 삭제
newcontents <- str_replace_all(newcontents, "[[:cntrl:]]", "")
#특수기호 삭제
newcontents <- str_replace_all(newcontents, "[[:punct:]]", "")
#숫자 = 삭제
newcontents <- str_replace_all(newcontents, "[[:digit:]]", "")
#괄호삭제
newcontents <- str_replace_all(newcontents, "\\(", "")
newcontents <- str_replace_all(newcontents, "\\)", "")
#따옴표 삭제
newcontents <- str_replace_all(newcontents, "'", "")
newcontents <- str_replace_all(newcontents, "'", "")
noun <- extractNoun(newcontents)
##불용어처리
txt_data <- gsub("//d+","",noun)
txt_data <- gsub("[[:cntrl:]]","",txt_data)
txt_data <- gsub("[[:punct:]]","",txt_data)
#이녀석이 숫자를 삭제해줍니다.
txt_data <- gsub("[[:digit:]]","",txt_data)
txt_data <- gsub("[[:lower:]]","",txt_data)
txt_data <- gsub("[[:upper:]]","",txt_data)
txt_data <- gsub("[A-z]","",txt_data)
txt_data <- gsub("'","",txt_data)
txt_data <- gsub("'","",txt_data)
txt_data <- gsub("‘","",txt_data)
txt_data <- gsub("’","",txt_data)
# head(txt_data)
myCorpus <- Corpus(VectorSource(txt_data))
myCorpus <- tm_map(myCorpus, removePunctuation)
myCorpus <- tm_map(myCorpus, removeNumbers)
myCorpus <- tm_map(myCorpus, tolower)
myCorpus <- tm_map(myCorpus, stripWhitespace)
WordList <- sapply(myCorpus, extractNoun, USE.NAMES=FALSE)
vectordata <- unlist(WordList)
vectordata <- Filter(function(x){nchar(x)>1}, vectordata)
# preview<- sort(table(vectordata), decreasing=TRUE,100)
# View(preview)
#빈도추출
wordcount <- table(vectordata)
# write.csv(wordcount,file="freq.csv")
#상위빈도로 정렬해서 result2로 명명
#result2 <- sort(wordcount, decreasing=TRUE)
# View(result2)
#누적빈도 알아보기
#cumsum.word.freq <-cumsum(result2)
#cumsum.word.freq[1:50]
#전체합이1이되는비율알아보기
#prop.word.freq <-cumsum.word.freq/cumsum.word.freq[length(cumsum.word.freq)]
#prop.word.freq[1:100]
#상위빈도 50단어 저장
result <- head(sort(wordcount, decreasing=TRUE), n=30)
#데이터프레임으로 변환
df.result <-data.frame(result)
#연도 추가
df.result$year <-year
#순위 추가
df.result$rank <-rank(df.result$Freq)
return(df.result)
} # ext50 펑션 정의 끝
#합치기
t <- Reduce(function(x,y) rbind(x, y), list(words1990, words1991, words1992))
View(t)
#합치기
t <- Reduce(function(x,y) rbind(x, y), list(words1990:words2018))
# 1990~2018 연도별 단어 추출
words <- vector("list", 29)
View(words)
words[1990]
for (val in year)
{
nam1 <- paste("data", val, sep ="")
#nam2 <- paste("words", val, sep ="")
assign(words[val], ext50(eval(parse(text=nam1)), val))
#print(nam2$일자)
}
words[1990]
words[[1990]]
x <- list(1:5)
View(x)
x[[1]]
x[1]
x
View(x)
for (val in 1:29)
{
nam1 <- paste("data", val, sep ="")
#nam2 <- paste("words", val, sep ="")
assign(words[val], ext50(eval(parse(text=nam1)), val))
#print(nam2$일자)
}
for (val in 1:29)
{
nam1 <- paste("data", val+1989, sep ="")
#nam2 <- paste("words", val, sep ="")
assign(words[val], ext50(eval(parse(text=nam1)), val))
#print(nam2$일자)
}
for (val in 1:29)
{
nam1 <- paste("data", val+1989, sep ="")
#nam2 <- paste("words", val, sep ="")
assign(words[[val]], ext50(eval(parse(text=nam1)), val))
#print(nam2$일자)
}
# 1990~2018 연도별 단어 추출
words <- vector("list", 29)
for (val in 1:29)
{
nam1 <- paste("data", val+1989, sep ="")
#nam2 <- paste("words", val, sep ="")
assign(words[[val]], ext50(eval(parse(text=nam1)), val))
#print(nam2$일자)
}
for (val in 1:29)
{
nam1 <- paste("data", val+1989, sep ="")
#nam2 <- paste("words", val, sep ="")
assign(words[val], ext50(eval(parse(text=nam1)), val))
#print(nam2$일자)
}
View(x)
View(y)
for (val in 1:29)
{
nam1 <- paste("data", val+1989, sep ="")
#nam2 <- paste("words", val, sep ="")
assign(words[val], ext50(eval(parse(text=nam1)), val+1989))
#print(nam2$일자)
}
for (val in 1:29)
{
nam1 <- paste("data", val+1989, sep ="")
#nam2 <- paste("words", val, sep ="")
assign("words[val]", ext50(eval(parse(text=nam1)), val+1989))
#print(nam2$일자)
}
View(words)
View(`words[val]`)
m <- ext50(data1990)
m <- ext50(data1990, 1990)
typeof(m)
View(m)
View(m)
typeof(words1990)
### tempdata에서 콘텐츠(본문) 부분만 따오기 이후의 코드를
### ext50 펑션으로 정의 그러나 톱 30으로 바꾸었음
ext50 <- function(data, year) {
contents <- data$'본문'
# head(contents)
#영문표현삭제
newcontents <- str_replace_all(contents, "[[:lower:]]", "")
#제어문자 삭제
newcontents <- str_replace_all(newcontents, "[[:cntrl:]]", "")
#특수기호 삭제
newcontents <- str_replace_all(newcontents, "[[:punct:]]", "")
#숫자 = 삭제
newcontents <- str_replace_all(newcontents, "[[:digit:]]", "")
#괄호삭제
newcontents <- str_replace_all(newcontents, "\\(", "")
newcontents <- str_replace_all(newcontents, "\\)", "")
#따옴표 삭제
newcontents <- str_replace_all(newcontents, "'", "")
newcontents <- str_replace_all(newcontents, "'", "")
noun <- extractNoun(newcontents)
##불용어처리
txt_data <- gsub("//d+","",noun)
txt_data <- gsub("[[:cntrl:]]","",txt_data)
txt_data <- gsub("[[:punct:]]","",txt_data)
#이녀석이 숫자를 삭제해줍니다.
txt_data <- gsub("[[:digit:]]","",txt_data)
txt_data <- gsub("[[:lower:]]","",txt_data)
txt_data <- gsub("[[:upper:]]","",txt_data)
txt_data <- gsub("[A-z]","",txt_data)
txt_data <- gsub("'","",txt_data)
txt_data <- gsub("'","",txt_data)
txt_data <- gsub("‘","",txt_data)
txt_data <- gsub("’","",txt_data)
# head(txt_data)
myCorpus <- Corpus(VectorSource(txt_data))
myCorpus <- tm_map(myCorpus, removePunctuation)
myCorpus <- tm_map(myCorpus, removeNumbers)
myCorpus <- tm_map(myCorpus, tolower)
myCorpus <- tm_map(myCorpus, stripWhitespace)
WordList <- sapply(myCorpus, extractNoun, USE.NAMES=FALSE)
vectordata <- unlist(WordList)
vectordata <- Filter(function(x){nchar(x)>1}, vectordata)
# preview<- sort(table(vectordata), decreasing=TRUE,100)
# View(preview)
#빈도추출
wordcount <- table(vectordata)
# write.csv(wordcount,file="freq.csv")
#상위빈도로 정렬해서 result2로 명명
#result2 <- sort(wordcount, decreasing=TRUE)
# View(result2)
#누적빈도 알아보기
#cumsum.word.freq <-cumsum(result2)
#cumsum.word.freq[1:50]
#전체합이1이되는비율알아보기
#prop.word.freq <-cumsum.word.freq/cumsum.word.freq[length(cumsum.word.freq)]
#prop.word.freq[1:100]
#상위빈도 30단어 저장
result <- head(sort(wordcount, decreasing=TRUE), n=30)
#데이터프레임으로 변환
#df.result <-data.frame(result)
#연도 추가
#df.result$year <-year
#순위 추가
#df.result$rank <-rank(df.result$Freq)
return(result)
} # ext50 펑션 정의 끝
m <- ext50(words1990, 1990)
View(`words[val]`)
m <- ext50(data1990, 1990)
typeof(m)
View(m)
assign(words[1], ext50(data1990, 1990))
assign(words[[1], ext50(data1990, 1990))
assign(words[[1]], ext50(data1990, 1990))
words[1]
words
words[[1]]
assign(words[[1]], ext50(data1990, 1990))
typeof(words)
#합치기
t <- Reduce(function(x,y) rbind(x, y), list(words1990, words1991, words1992))
View(t)
write.csv(t, file="t.csv")
getwd()
